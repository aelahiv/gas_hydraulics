"""Historical Analysis Plugin for QGIS.

This plugin provides historical load analysis over time by 5-year periods.
Uses Install Date from service point list to determine when loads came online.
Aggregates by class and area for past periods.
"""
from __future__ import annotations
import logging
from typing import Any, Dict, List
import pandas as pd
from datetime import datetime
import os

LOGGER = logging.getLogger(__name__)

# Import validation functions
try:
    from .data_validation import (
        DataValidator,
        validate_layer_data,
        show_validation_dialog,
        safe_int
    )
    VALIDATION_AVAILABLE = True
except ImportError:
    LOGGER.warning("Data validation module not available")
    VALIDATION_AVAILABLE = False
    # Fallback safe_int
    def safe_int(value, default=None):
        try:
            return int(float(value)) if value is not None else default
        except (ValueError, TypeError):
            return default

class HistoricalAnalysisPlugin:
    def __init__(self, iface: Any = None):
        """Initialize the Historical Analysis plugin."""
        self.iface = iface
        self.action = None
        
        # Default load calculation parameters
        self.load_multiplier = 1.07
        self.heat_factor_multiplier = 56.8
        
    def initGui(self):
        """Create GUI elements (only when running inside QGIS)."""
        try:
            from qgis.PyQt.QtWidgets import QAction
            self.action = QAction("Historical Analysis", self.iface.mainWindow() if self.iface else None)
            self.action.triggered.connect(self.run)
            if self.iface:
                # Add to menu/toolbar in real implementation
                pass
        except Exception:
            LOGGER.debug("QGIS not available; skipping GUI setup")

    def unload(self):
        """Cleanup GUI items."""
        try:
            if self.action and self.iface:
                # Remove from menu/toolbar
                pass
        except Exception:
            LOGGER.debug("QGIS not available; skipping unload")

    def export_table_to_csv(self, table, default_filename="table_export"):
        """Export QTableWidget contents to CSV file."""
        try:
            from qgis.PyQt.QtWidgets import QFileDialog, QMessageBox
            
            # Get save file path
            file_path, _ = QFileDialog.getSaveFileName(
                self.iface.mainWindow() if self.iface else None,
                "Export Table to CSV",
                f"{default_filename}.csv",
                "CSV Files (*.csv);;All Files (*)"
            )
            
            if not file_path:
                return
            
            # Extract table data
            import csv
            
            with open(file_path, 'w', newline='', encoding='utf-8') as csvfile:
                writer = csv.writer(csvfile)
                
                # Write headers
                headers = []
                for col in range(table.columnCount()):
                    headers.append(table.horizontalHeaderItem(col).text())
                writer.writerow(headers)
                
                # Write data rows
                for row in range(table.rowCount()):
                    row_data = []
                    for col in range(table.columnCount()):
                        item = table.item(row, col)
                        row_data.append(item.text() if item else "")
                    writer.writerow(row_data)
            
            if self.iface:
                QMessageBox.information(
                    self.iface.mainWindow(),
                    "Export Successful",
                    f"Table exported to:\n{file_path}"
                )
            
            LOGGER.info(f"Table exported to CSV: {file_path}")
            
        except Exception as e:
            LOGGER.error(f"Error exporting table to CSV: {e}")
            if self.iface:
                from qgis.PyQt.QtWidgets import QMessageBox
                QMessageBox.critical(
                    self.iface.mainWindow(),
                    "Export Error",
                    f"Failed to export table:\n{str(e)}"
                )

    def calculate_load(self, df: pd.DataFrame, factor_codes_to_keep: List[str] = None) -> pd.DataFrame:
        """Calculate load for service points using the specified formula.
        
        Args:
            df: DataFrame with service point data
            factor_codes_to_keep: List of factor codes to keep Base Factor and Heat Factor (others get zeroed)
            
        Returns:
            DataFrame with calculated Load column
        """
        if factor_codes_to_keep is None:
            factor_codes_to_keep = ['0', '1', '20']  # Only these codes keep their factors
            
        df = df.copy()
        
        # Zero out Base Factor and Heat Factor for codes NOT in the keep list
        mask = ~df['Factor Code'].astype(str).isin(factor_codes_to_keep)
        df.loc[mask, 'Base Factor'] = 0
        df.loc[mask, 'Heat Factor'] = 0
        
        # Fill NaN values in HUC 3-Year Peak Demand with 0
        df['HUC 3-Year Peak Demand'] = df['HUC 3-Year Peak Demand'].fillna(0)
        
        # Calculate load using the formula
        df['Load'] = (self.load_multiplier * 
                     (df['Base Factor'] + self.heat_factor_multiplier * df['Heat Factor']) + 
                     df['HUC 3-Year Peak Demand'])
        
        return df

    def filter_by_use_class(self, df: pd.DataFrame) -> Dict[str, pd.DataFrame]:
        """Filter DataFrame by use class categories."""
        df_res = df[df['Use Class'].str.contains('APT|RES', na=False)]
        df_ind = df[df['Use Class'].str.contains('IND', na=False)]
        df_comm = df[df['Use Class'].str.contains('COM', na=False)]
        
        return {
            'residential': df_res,
            'industrial': df_ind,
            'commercial': df_comm
        }

    def get_5year_periods(self, start_year: int, end_year: int) -> List[int]:
        """Generate list of 5-year period end years."""
        periods = []
        current = start_year
        while current <= end_year:
            periods.append(current)
            current += 5
        # Add final year if it doesn't align with 5-year periods
        if periods[-1] != end_year:
            periods.append(end_year)
        return periods

    def export_detailed_csv(self, excel_file_path: str, zone_layer: Any = None, 
                           pipe_layer: Any = None, start_year: int = 2000, 
                           end_year: int = 2025) -> str:
        """Export comprehensive CSV with load by polygon by category by year.
        
        Args:
            excel_file_path: Path to Excel file with service point data
            zone_layer: QGIS layer with zone polygons  
            pipe_layer: QGIS layer with pipe lines
            start_year: Start year for analysis
            end_year: End year for analysis
            
        Returns:
            Path to exported CSV file or empty string if failed
        """
        try:
            LOGGER.info(f"Starting detailed CSV export for {start_year}-{end_year}")
            
            # Load and process Excel data
            df = pd.read_excel(excel_file_path)
            original_count = len(df)
            LOGGER.info(f"Loaded Excel file: {original_count} rows")
            
            if df.empty:
                LOGGER.error("Excel file is empty")
                return ""
            
            # Calculate loads for each service point
            df = self.calculate_load(df)
            LOGGER.info(f"Calculated loads for {len(df)} service points")
            
            # Convert Install Date and filter by years
            df['Install Date'] = pd.to_datetime(df['Install Date'], errors='coerce')
            df = df.dropna(subset=['Install Date'])
            df['Install Year'] = df['Install Date'].dt.year
            
            # Filter to analysis period
            period_df = df[(df['Install Year'] >= start_year) & (df['Install Year'] <= end_year)]
            LOGGER.info(f"Filtered to analysis period: {len(period_df)} rows")
            
            if period_df.empty:
                LOGGER.error("No data in analysis period")
                return ""
            
            # Filter by use class
            class_dfs = self.filter_by_use_class(period_df)
            
            # Prepare detailed results
            detailed_results = []
            
            if zone_layer and pipe_layer:
                LOGGER.info("Processing zones for detailed CSV export...")
                
                for zone_feature in zone_layer.getFeatures():
                    # Get zone name
                    zone_name = self._get_zone_name(zone_feature)
                    
                    # Find pipes in this zone
                    pipe_names = self.get_pipes_in_zone(zone_feature, pipe_layer)
                    LOGGER.info(f"Zone {zone_name}: Found {len(pipe_names)} pipes")
                    
                    # Process each year and class combination
                    for year in range(start_year, end_year + 1):
                        for class_name, class_df in class_dfs.items():
                            # Get cumulative load up to this year for this zone
                            zone_year_df = class_df[
                                (class_df['Distribution Pipe'].isin(pipe_names)) &
                                (class_df['Install Year'] <= year)
                            ]
                            
                            cumulative_load = zone_year_df['Load'].sum()
                            
                            # Add to results
                            detailed_results.append({
                                'Polygon': zone_name,
                                'Year': year,
                                'Category': class_name.title(),
                                'Cumulative_Load_GJ': round(cumulative_load, 2),
                                'New_Load_This_Year_GJ': 0  # Will calculate below
                            })
            else:
                LOGGER.info("No spatial layers - creating overall totals")
                # If no spatial layers, create overall totals
                for year in range(start_year, end_year + 1):
                    for class_name, class_df in class_dfs.items():
                        year_df = class_df[class_df['Install Year'] <= year]
                        cumulative_load = year_df['Load'].sum()
                        
                        detailed_results.append({
                            'Polygon': 'Overall',
                            'Year': year,
                            'Category': class_name.title(),
                            'Cumulative_Load_GJ': round(cumulative_load, 2),
                            'New_Load_This_Year_GJ': 0
                        })
            
            # Calculate new loads for each year (difference from previous year)
            results_df = pd.DataFrame(detailed_results)
            results_df = results_df.sort_values(['Polygon', 'Category', 'Year'])
            
            for polygon in results_df['Polygon'].unique():
                for category in results_df['Category'].unique():
                    mask = (results_df['Polygon'] == polygon) & (results_df['Category'] == category)
                    polygon_category_data = results_df[mask].copy()
                    
                    if len(polygon_category_data) > 0:
                        # Calculate new load as difference from previous year
                        polygon_category_data['New_Load_This_Year_GJ'] = polygon_category_data['Cumulative_Load_GJ'].diff().fillna(polygon_category_data['Cumulative_Load_GJ'])
                        results_df.loc[mask, 'New_Load_This_Year_GJ'] = polygon_category_data['New_Load_This_Year_GJ']
            
            # Export to CSV
            if self.iface:
                from qgis.PyQt.QtWidgets import QFileDialog
                csv_path, _ = QFileDialog.getSaveFileName(
                    self.iface.mainWindow(),
                    "Export Detailed Historical Analysis",
                    f"historical_analysis_{start_year}_{end_year}.csv",
                    "CSV Files (*.csv)"
                )
            else:
                csv_path = f"historical_analysis_{start_year}_{end_year}.csv"
            
            if csv_path:
                results_df.to_csv(csv_path, index=False)
                LOGGER.info(f"Exported detailed CSV to: {csv_path}")
                return csv_path
            
            return ""
            
        except Exception as e:
            LOGGER.error(f"Error creating detailed CSV export: {e}")
            return ""
    
    def _get_zone_name(self, zone_feature):
        """Get zone name from feature attributes, prioritizing Name column."""
        zone_name = None
        possible_name_fields = ['Name', 'name', 'NAME', 'zone_name', 'Zone_Name', 'ZONE_NAME',
                              'zone', 'Zone', 'ZONE', 'area_name', 'Area_Name', 'AREA_NAME',
                              'id', 'ID', 'fid', 'FID', 'objectid', 'OBJECTID']
        
        for field_name in possible_name_fields:
            try:
                zone_name = zone_feature.attribute(field_name)
                if zone_name is not None and str(zone_name).strip():
                    break
            except:
                continue
        
        if zone_name is None:
            zone_name = f"Zone_{zone_feature.id()}"
            
        return str(zone_name)

    def analyze_historical_loads_by_period(self, excel_file_path: str, zone_layer=None, 
                                         pipe_layer=None, start_year: int = 2000, 
                                         end_year: int = 2025) -> Dict[str, Dict[str, Dict[str, float]]]:
        """Analyze historical loads by 5-year periods.
        
        Args:
            excel_file_path: Path to Excel file with service point list
            zone_layer: QGIS polygon layer with subzones
            pipe_layer: QGIS vector layer with pipes
            start_year: Start year for analysis
            end_year: End year for analysis
            
        Returns:
            Dictionary mapping periods to zones to load by class
            Format: {period: {zone: {class: load}}}
        """
        try:
            LOGGER.info(f"=== STARTING HISTORICAL ANALYSIS ===")
            LOGGER.info(f"Excel file: {excel_file_path}")
            LOGGER.info(f"Analysis period: {start_year} to {end_year}")
            
            # Read Excel file
            df = pd.read_excel(excel_file_path, sheet_name='Service Point List')
            LOGGER.info(f"Loaded {len(df)} service points from Excel")
            
            if df.empty:
                LOGGER.error("Excel file contains no data")
                return {}
            
            # Calculate loads
            df = self.calculate_load(df)
            total_load = df['Load'].sum()
            LOGGER.info(f"Total calculated load: {total_load:.2f}")
            
            if total_load == 0:
                LOGGER.warning("All calculated loads are zero - check factor code logic")
            
            # Parse install dates
            LOGGER.info("Processing install dates...")
            original_count = len(df)
            df['Install Date'] = pd.to_datetime(df['Install Date'], errors='coerce')
            
            # Count invalid dates
            invalid_dates = df['Install Date'].isna().sum()
            LOGGER.info(f"Found {invalid_dates} invalid/missing install dates out of {original_count}")
            
            if invalid_dates == original_count:
                LOGGER.error("No valid install dates found - all data would be dropped")
                return {}
            
            # Only drop if we have some valid dates
            if invalid_dates > 0:
                LOGGER.warning(f"Dropping {invalid_dates} rows with invalid install dates")
                df = df.dropna(subset=['Install Date'])
            
            df['Install Year'] = df['Install Date'].dt.year
            
            # Show date range in data
            min_year = df['Install Year'].min()
            max_year = df['Install Year'].max()
            LOGGER.info(f"Data date range: {min_year} to {max_year}")
            
            # Filter to analysis period
            period_df = df[(df['Install Year'] >= start_year) & (df['Install Year'] <= end_year)]
            LOGGER.info(f"After period filter ({start_year}-{end_year}): {len(period_df)} points")
            
            if period_df.empty:
                LOGGER.error(f"No data found in analysis period {start_year}-{end_year}")
                LOGGER.info(f"Available data spans {min_year}-{max_year}")
                return {}
            
            # Get 5-year periods
            periods = self.get_5year_periods(start_year, end_year)
            LOGGER.info(f"Analysis periods: {periods}")
            
            # Filter by use class
            class_dfs = self.filter_by_use_class(period_df)
            
            for class_name, class_df in class_dfs.items():
                class_load = class_df['Load'].sum()
                LOGGER.info(f"{class_name}: {len(class_df)} points, load: {class_load:.2f}")
            
            # Initialize results
            period_results = {}
            
            for period_end in periods:
                period_start = period_end - 4
                period_name = f"{period_start}-{period_end}"
                LOGGER.info(f"Processing period: {period_name}")
                
                # Get cumulative data up to end of period (loads that came online by this period)
                period_data = {}
                
                if zone_layer and pipe_layer:
                    LOGGER.info("Processing spatial zones...")
                    zone_count = 0
                    # Process each zone
                    for zone_feature in zone_layer.getFeatures():
                        zone_count += 1
                        
                        # Try different field names for zone identification, prioritizing "Name" column
                        zone_name = None
                        # Prioritize "Name" column variants, then fall back to other identifiers
                        possible_name_fields = ['Name', 'name', 'NAME', 'zone_name', 'Zone_Name', 'ZONE_NAME',
                                              'zone', 'Zone', 'ZONE', 'area_name', 'Area_Name', 'AREA_NAME',
                                              'id', 'ID', 'fid', 'FID', 'objectid', 'OBJECTID']
                        
                        for field_name in possible_name_fields:
                            try:
                                zone_name = zone_feature.attribute(field_name)
                                if zone_name is not None and str(zone_name).strip():
                                    LOGGER.info(f"Found zone name '{zone_name}' in field '{field_name}'")
                                    break
                            except:
                                continue
                        
                        if zone_name is None:
                            zone_name = f"Zone_{zone_count}"
                        
                        # Find pipes in this zone
                        pipe_names = self.get_pipes_in_zone(zone_feature, pipe_layer)
                        LOGGER.info(f"Zone {zone_name}: Found {len(pipe_names)} pipes")
                        
                        # Calculate cumulative loads by class for this zone up to period end
                        zone_class_loads = {}
                        for class_name, class_df in class_dfs.items():
                            # Filter by zone pipes and install year <= period_end
                            zone_period_df = class_df[
                                (class_df['Distribution Pipe'].isin(pipe_names)) &
                                (class_df['Install Year'] <= period_end)
                            ]
                            zone_load = zone_period_df['Load'].sum()
                            zone_class_loads[class_name] = zone_load
                            
                            if len(zone_period_df) > 0:
                                LOGGER.info(f"  {class_name}: {len(zone_period_df)} points, load: {zone_load:.2f}")
                        
                        period_data[zone_name] = zone_class_loads
                else:
                    LOGGER.info("No spatial layers - using overall totals")
                    # If no spatial layers, return overall totals
                    overall_loads = {}
                    for class_name, class_df in class_dfs.items():
                        period_class_df = class_df[class_df['Install Year'] <= period_end]
                        class_load = period_class_df['Load'].sum()
                        overall_loads[class_name] = class_load
                        LOGGER.info(f"  {class_name} (cumulative to {period_end}): {len(period_class_df)} points, load: {class_load:.2f}")
                    period_data['Total'] = overall_loads
                
                period_results[period_name] = period_data
            
            LOGGER.info(f"=== HISTORICAL ANALYSIS COMPLETE ===")
            LOGGER.info(f"Generated {len(period_results)} periods")
            
            return period_results
            
        except Exception as e:
            LOGGER.error(f"Error analyzing historical loads: {e}")
            import traceback
            LOGGER.error(f"Traceback: {traceback.format_exc()}")
            return {}

    def get_pipes_in_zone(self, zone_feature, pipe_layer, buffer_pixels: int = 10):
        """Find pipes that intersect with a zone polygon using a buffer.
        
        Args:
            zone_feature: Zone polygon feature
            pipe_layer: QGIS vector layer with pipe data
            buffer_pixels: Buffer size in pixels to prevent undercounting
            
        Returns:
            List of pipe names that intersect the zone
        """
        try:
            # Check if we have QGIS available
            try:
                from qgis.core import QgsGeometry
                qgis_available = True
            except ImportError:
                qgis_available = False
                LOGGER.warning("QGIS not available for spatial operations")
                return []
            
            if not qgis_available:
                return []
            
            # Get zone geometry
            zone_geom = zone_feature.geometry()
            if zone_geom.isEmpty():
                LOGGER.warning("Zone geometry is empty")
                return []
            
            LOGGER.info(f"Zone geometry type: {zone_geom.wkbType()}")
            LOGGER.info(f"Zone bounds: {zone_geom.boundingBox().toString()}")
            
            # Create buffer (convert pixels to map units - this is approximate)
            # In a real implementation, you'd convert pixels to map units based on canvas scale
            buffer_distance = buffer_pixels * 0.1  # Approximate conversion
            buffered_geom = zone_geom.buffer(buffer_distance, 5)
            
            LOGGER.info(f"Created buffer of {buffer_distance} units")
            
            pipe_names = []
            intersecting_count = 0
            total_pipes = 0
            
            # Check each pipe feature for intersection
            for pipe_feature in pipe_layer.getFeatures():
                total_pipes += 1
                pipe_geom = pipe_feature.geometry()
                
                if pipe_geom.isEmpty():
                    continue
                
                # Check if pipe intersects buffered zone
                if buffered_geom.intersects(pipe_geom):
                    intersecting_count += 1
                    
                    # Try to get pipe name/identifier from various possible fields
                    pipe_name = None
                    # Your pipe layer uses FacNam1005 for facility names that match Excel Distribution Pipe
                    possible_name_fields = ['FacNam1005', 'name', 'Name', 'NAME', 'pipe_name', 'Pipe_Name', 'PIPE_NAME',
                                          'id', 'ID', 'fid', 'FID', 'objectid', 'OBJECTID', 'pipe_id', 'PIPE_ID',
                                          'facilityid', 'FACILITYID', 'facility_id', 'FACILITY_ID']
                    
                    for field_name in possible_name_fields:
                        try:
                            pipe_name = pipe_feature.attribute(field_name)
                            if pipe_name is not None and str(pipe_name).strip():
                                # Log which field we're using for debugging
                                if intersecting_count <= 5:  # Only log first few for debugging
                                    LOGGER.info(f"  Using field '{field_name}' for pipe name: {pipe_name}")
                                break
                        except:
                            continue
                    
                    if pipe_name is None:
                        pipe_name = f"Pipe_{pipe_feature.id()}"
                        LOGGER.warning(f"  No name field found, using fallback: {pipe_name}")
                    
                    pipe_names.append(str(pipe_name))
            
            LOGGER.info(f"Spatial intersection results:")
            LOGGER.info(f"  Total pipes checked: {total_pipes}")
            LOGGER.info(f"  Intersecting pipes: {intersecting_count}")
            LOGGER.info(f"  Pipe names found: {len(pipe_names)}")
            if len(pipe_names) > 0:
                LOGGER.info(f"  Sample pipe names: {pipe_names[:5]}")
            
            return pipe_names
            
        except Exception as e:
            LOGGER.error(f"Error finding pipes in zone: {e}")
            import traceback
            LOGGER.error(f"Traceback: {traceback.format_exc()}")
            return []

    def create_historical_analysis_output(self, period_results: Dict[str, Dict[str, Dict[str, float]]]):
        """Create output showing historical load trends."""
        try:
            # This would create tables/charts showing:
            # - Load growth over time by zone and class
            # - Cumulative load by period
            # - Growth rates between periods
            
            LOGGER.info("Creating historical analysis output")
            for period, zones in period_results.items():
                LOGGER.info(f"Period {period}:")
                for zone, loads in zones.items():
                    total_load = sum(loads.values())
                    LOGGER.info(f"  {zone}: Total {total_load:.2f} ({loads})")
                    
        except Exception as e:
            LOGGER.error(f"Error creating historical output: {e}")

    def run(self):
        """Run the Historical Analysis plugin."""
        try:
            LOGGER.info("Running Historical Analysis")
            
            if self.iface:
                # Show GUI dialog to get user inputs
                success, inputs = self.show_input_dialog()
                if not success:
                    return
                
                # Validate inputs
                if VALIDATION_AVAILABLE:
                    LOGGER.info("üîç Validating historical analysis inputs...")
                    validator = DataValidator()
                    
                    # Check Excel file
                    if not inputs.get('excel_file'):
                        validator.add_error("No Excel file specified")
                    elif not os.path.exists(inputs['excel_file']):
                        validator.add_error(f"Excel file not found: {inputs['excel_file']}")
                    else:
                        validator.add_info(f"Excel file: {os.path.basename(inputs['excel_file'])}")
                    
                    # Check years
                    start_year = safe_int(inputs.get('start_year'), 2000)
                    end_year = safe_int(inputs.get('end_year'), 2025)
                    
                    if start_year >= end_year:
                        validator.add_error(f"Start year ({start_year}) must be before end year ({end_year})")
                    else:
                        year_span = end_year - start_year
                        validator.add_info(f"Analysis period: {year_span} years ({start_year} - {end_year})")
                        
                        if year_span > 50:
                            validator.add_warning(f"Long analysis period: {year_span} years - may take longer to process")
                    
                    # Validate zone layer
                    if inputs.get('zone_layer'):
                        zone_validator = validate_layer_data(
                            inputs['zone_layer'],
                            "Zone Layer",
                            required_fields=None  # Will check for basic validity
                        )
                        validator.errors.extend(zone_validator.errors)
                        validator.warnings.extend(zone_validator.warnings)
                        validator.info.extend(zone_validator.info)
                    else:
                        validator.add_error("No zone layer selected")
                    
                    # Validate pipe layer
                    if inputs.get('pipe_layer'):
                        pipe_validator = validate_layer_data(
                            inputs['pipe_layer'],
                            "Pipe Layer",
                            required_fields=None
                        )
                        validator.errors.extend(pipe_validator.errors)
                        validator.warnings.extend(pipe_validator.warnings)
                        validator.info.extend(pipe_validator.info)
                    else:
                        validator.add_error("No pipe layer selected")
                    
                    # Show validation dialog
                    if not show_validation_dialog(validator, 
                                                  title="Historical Analysis - Data Validation",
                                                  parent=self.iface.mainWindow()):
                        LOGGER.info("‚ùå User cancelled after validation")
                        return
                
                # Check if user wants detailed CSV export
                if inputs.get('export_csv', False):
                    # Export detailed CSV
                    csv_path = self.export_detailed_csv(
                        excel_file_path=inputs['excel_file'],
                        zone_layer=inputs['zone_layer'],
                        pipe_layer=inputs['pipe_layer'],
                        start_year=inputs['start_year'],
                        end_year=inputs['end_year']
                    )
                    
                    if csv_path:
                        from qgis.PyQt.QtWidgets import QMessageBox
                        QMessageBox.information(
                            self.iface.mainWindow(),
                            "CSV Export Complete",
                            f"Detailed historical analysis exported to:\n{csv_path}\n\n"
                            f"The CSV contains load data by polygon, category, and year from {inputs['start_year']} to {inputs['end_year']}."
                        )
                    else:
                        from qgis.PyQt.QtWidgets import QMessageBox
                        QMessageBox.warning(
                            self.iface.mainWindow(),
                            "CSV Export Failed",
                            "Failed to export CSV. Check the log for details."
                        )
                else:
                    # Process the data with user inputs for standard analysis
                    historical_data = self.analyze_historical_loads_by_period(
                        excel_file_path=inputs['excel_file'],
                        zone_layer=inputs['zone_layer'],
                        pipe_layer=inputs['pipe_layer'],
                        start_year=inputs['start_year'],
                        end_year=inputs['end_year']
                    )
                    
                    if historical_data:
                        # Show results dialog
                        self.show_results_dialog(historical_data)
                    else:
                        from qgis.PyQt.QtWidgets import QMessageBox
                        QMessageBox.warning(
                            self.iface.mainWindow(),
                            "No Historical Data Found", 
                            "No historical data could be processed.\n\n"
                            "Common causes:\n"
                            "‚Ä¢ Install dates are missing or invalid in Excel file\n"
                        "‚Ä¢ No data found in the selected year range\n"
                        "‚Ä¢ All loads calculated as zero (check factor codes)\n"
                        "‚Ä¢ Missing required columns in Excel file\n\n"
                        "Check the QGIS log panel for detailed debugging information."
                    )
            else:
                print("Historical Analysis plugin executed successfully")
                
        except Exception as e:
            LOGGER.error(f"Error running Historical Analysis: {e}")
            if self.iface:
                from qgis.PyQt.QtWidgets import QMessageBox
                QMessageBox.critical(
                    self.iface.mainWindow(),
                    "Error",
                    f"Error running analysis: {str(e)}"
                )

    def show_input_dialog(self):
        """Show dialog to get user inputs for the historical analysis."""
        try:
            from qgis.PyQt.QtWidgets import (QDialog, QVBoxLayout, QHBoxLayout, QLabel, 
                                           QLineEdit, QPushButton, QComboBox, QSpinBox,
                                           QDoubleSpinBox, QFileDialog, QGroupBox, QFormLayout,
                                           QFrame)
            from qgis.PyQt.QtCore import Qt
            from qgis.PyQt.QtGui import QFont
            from qgis.core import QgsProject
            
            dialog = QDialog(self.iface.mainWindow())
            dialog.setWindowTitle("Historical Analysis - Input Selection")
            dialog.setMinimumSize(650, 550)
            
            layout = QVBoxLayout()
            
            # Title
            title_label = QLabel("üìä Historical Load Analysis")
            title_font = QFont()
            title_font.setPointSize(13)
            title_font.setBold(True)
            title_label.setFont(title_font)
            layout.addWidget(title_label)
            
            # Description
            desc_label = QLabel(
                "Analyze historical service point data to understand past load growth trends:\n\n"
                "üìà Processes multiple years of customer data to calculate actual load changes\n"
                "üó∫Ô∏è Aggregates results by geographic zones and customer categories\n"
                "üìâ Generates trend analysis for informed future projections\n\n"
                "üí° This analysis helps validate and refine forecasting parameters"
            )
            desc_label.setWordWrap(True)
            desc_label.setStyleSheet("color: #666; padding: 10px; background-color: #f0f0f0; border-radius: 5px;")
            layout.addWidget(desc_label)
            
            # Separator
            line = QFrame()
            line.setFrameShape(QFrame.HLine)
            line.setFrameShadow(QFrame.Sunken)
            layout.addWidget(line)
            
            # File selection group
            file_group = QGroupBox("üìÑ Input Data Source")
            file_layout = QFormLayout()
            
            # Excel file selection
            excel_layout = QHBoxLayout()
            self.excel_line = QLineEdit()
            self.excel_line.setPlaceholderText("Select Excel file with historical service point data...")
            excel_browse = QPushButton("üìÅ Browse...")
            excel_browse.clicked.connect(self.browse_excel_file)
            excel_browse.setToolTip("Browse for Excel file containing historical service point records")
            excel_layout.addWidget(self.excel_line)
            excel_layout.addWidget(excel_browse)
            
            excel_label = QLabel("üìã Service Point List (Excel):")
            excel_label.setToolTip(
                "Excel file containing historical service point records\n"
                "Required columns: Location, Category, Date/Year, Load values"
            )
            file_layout.addRow(excel_label, excel_layout)
            
            file_group.setLayout(file_layout)
            layout.addWidget(file_group)
            
            # Layer selection group
            layer_group = QGroupBox("üó∫Ô∏è Spatial Layers")
            layer_layout = QFormLayout()
            
            # Zone layer selection
            self.zone_combo = QComboBox()
            self.populate_layer_combo(self.zone_combo, "Polygon")
            self.zone_combo.setToolTip(
                "Polygon layer defining analysis zones\n"
                "Service points will be aggregated within these zones"
            )
            layer_layout.addRow("üìç Zone Layer (Polygons):", self.zone_combo)
            
            # Pipe layer selection
            self.pipe_combo = QComboBox()
            self.populate_layer_combo(self.pipe_combo, "LineString")
            self.pipe_combo.setToolTip(
                "Pipe network layer for spatial analysis\n"
                "Used for infrastructure context and reporting"
            )
            layer_layout.addRow("üîß Pipe Layer (Lines):", self.pipe_combo)
            
            layer_group.setLayout(layer_layout)
            layout.addWidget(layer_group)
            
            # Parameters group
            param_group = QGroupBox("‚öôÔ∏è Analysis Parameters")
            param_layout = QFormLayout()
            
            # Load multiplier
            self.load_multiplier_spin = QDoubleSpinBox()
            self.load_multiplier_spin.setDecimals(3)
            self.load_multiplier_spin.setRange(0.001, 10.0)
            self.load_multiplier_spin.setValue(self.load_multiplier)
            self.load_multiplier_spin.setToolTip(
                "Multiplier applied to all load values\n"
                "Use for unit conversion or scaling (e.g., 1.0 = no change)"
            )
            param_layout.addRow("üî¢ Load Multiplier:", self.load_multiplier_spin)
            
            # Heat factor multiplier
            self.heat_multiplier_spin = QDoubleSpinBox()
            self.heat_multiplier_spin.setDecimals(1)
            self.heat_multiplier_spin.setRange(0.1, 200.0)
            self.heat_multiplier_spin.setValue(self.heat_factor_multiplier)
            self.heat_multiplier_spin.setToolTip(
                "Multiplier for heat factor calculations\n"
                "Adjusts peak demand estimation based on local conditions"
            )
            param_layout.addRow("üå°Ô∏è Heat Factor Multiplier:", self.heat_multiplier_spin)
            
            # Start year
            self.start_year_spin = QSpinBox()
            self.start_year_spin.setRange(1990, 2030)
            self.start_year_spin.setValue(2000)
            self.start_year_spin.setToolTip(
                "First year to include in the analysis\n"
                "Earlier years will be filtered out"
            )
            param_layout.addRow("üìÖ Start Year:", self.start_year_spin)
            
            # End year
            self.end_year_spin = QSpinBox()
            self.end_year_spin.setRange(2000, 2050)
            self.end_year_spin.setValue(2025)
            self.end_year_spin.setToolTip(
                "Last year to include in the analysis\n"
                "Later years will be filtered out"
            )
            param_layout.addRow("üìÖ End Year:", self.end_year_spin)
            
            param_group.setLayout(param_layout)
            layout.addWidget(param_group)
            
            # Export options group
            export_group = QGroupBox("üíæ Output Options")
            export_layout = QFormLayout()
            
            from qgis.PyQt.QtWidgets import QCheckBox
            self.csv_export_checkbox = QCheckBox("Export detailed CSV report")
            self.csv_export_checkbox.setToolTip(
                "Generate comprehensive CSV file with:\n"
                "‚Ä¢ Load by polygon\n"
                "‚Ä¢ Load by customer category\n"
                "‚Ä¢ Load by year\n"
                "Useful for external analysis and visualization"
            )
            export_layout.addRow(self.csv_export_checkbox)
            
            export_group.setLayout(export_layout)
            layout.addWidget(export_group)
            
            # Buttons
            button_layout = QHBoxLayout()
            ok_button = QPushButton("Run Analysis")
            csv_button = QPushButton("Export CSV Only")
            cancel_button = QPushButton("Cancel")
            
            ok_button.clicked.connect(dialog.accept)
            csv_button.clicked.connect(lambda: self._set_csv_export_and_accept(dialog))
            cancel_button.clicked.connect(dialog.reject)
            
            button_layout.addWidget(ok_button)
            button_layout.addWidget(csv_button)
            button_layout.addWidget(cancel_button)
            layout.addLayout(button_layout)
            
            dialog.setLayout(layout)
            
            # Execute dialog
            if dialog.exec_() == QDialog.Accepted:
                # Update plugin parameters
                self.load_multiplier = self.load_multiplier_spin.value()
                self.heat_factor_multiplier = self.heat_multiplier_spin.value()
                
                # Get selected layers
                zone_layer = None
                pipe_layer = None
                
                if self.zone_combo.currentText() != "":
                    zone_layer = QgsProject.instance().mapLayersByName(self.zone_combo.currentText())[0]
                if self.pipe_combo.currentText() != "":
                    pipe_layer = QgsProject.instance().mapLayersByName(self.pipe_combo.currentText())[0]
                
                return True, {
                    'excel_file': self.excel_line.text(),
                    'zone_layer': zone_layer,
                    'pipe_layer': pipe_layer,
                    'start_year': self.start_year_spin.value(),
                    'end_year': self.end_year_spin.value(),
                    'export_csv': getattr(self, '_csv_export_requested', False)
                }
            else:
                return False, {}
                
        except Exception as e:
            LOGGER.error(f"Error showing input dialog: {e}")
            return False, {}

    def _set_csv_export_and_accept(self, dialog):
        """Set CSV export flag and accept dialog."""
        self._csv_export_requested = True
        dialog.accept()

    def browse_excel_file(self):
        """Browse for Excel file."""
        try:
            from qgis.PyQt.QtWidgets import QFileDialog
            
            file_path, _ = QFileDialog.getOpenFileName(
                self.iface.mainWindow(),
                "Select Excel File",
                "",
                "Excel Files (*.xlsx *.xls);;All Files (*)"
            )
            
            if file_path:
                self.excel_line.setText(file_path)
                
        except Exception as e:
            LOGGER.error(f"Error browsing for Excel file: {e}")

    def populate_layer_combo(self, combo, geometry_type):
        """Populate combo box with layers of specified geometry type."""
        try:
            from qgis.core import QgsProject, QgsWkbTypes
            
            combo.clear()
            combo.addItem("")  # Empty option
            
            for layer in QgsProject.instance().mapLayers().values():
                if hasattr(layer, 'geometryType'):
                    if geometry_type == "Polygon" and layer.geometryType() == QgsWkbTypes.PolygonGeometry:
                        combo.addItem(layer.name())
                    elif geometry_type == "LineString" and layer.geometryType() == QgsWkbTypes.LineGeometry:
                        combo.addItem(layer.name())
                        
        except Exception as e:
            LOGGER.error(f"Error populating layer combo: {e}")

    def show_results_dialog(self, historical_data):
        """Show results dialog with historical analysis."""
        try:
            from qgis.PyQt.QtWidgets import (QDialog, QVBoxLayout, QTextEdit, QPushButton,
                                           QTableWidget, QTableWidgetItem, QTabWidget)
            
            dialog = QDialog(self.iface.mainWindow())
            dialog.setWindowTitle("Historical Analysis - Results")
            dialog.setMinimumSize(700, 500)
            
            layout = QVBoxLayout()
            
            # Create tab widget
            tab_widget = QTabWidget()
            
            # Summary tab
            summary_text = QTextEdit()
            summary_text.setReadOnly(True)
            
            summary_content = "HISTORICAL ANALYSIS RESULTS\n"
            summary_content += "=" * 50 + "\n\n"
            
            for period, zones in historical_data.items():
                summary_content += f"Period: {period}\n"
                summary_content += "-" * 30 + "\n"
                
                for zone_name, loads in zones.items():
                    total_load = sum(loads.values())
                    summary_content += f"  {zone_name}:\n"
                    summary_content += f"    Residential: {loads.get('residential', 0):.2f} GJ/d\n"
                    summary_content += f"    Commercial:  {loads.get('commercial', 0):.2f} GJ/d\n"
                    summary_content += f"    Industrial:  {loads.get('industrial', 0):.2f} GJ/d\n"
                    summary_content += f"    Total:       {total_load:.2f} GJ/d\n\n"
                
                summary_content += "\n"
            
            summary_text.setPlainText(summary_content)
            tab_widget.addTab(summary_text, "Summary")
            
            # Create table for each period
            for period, zones in historical_data.items():
                table = QTableWidget()
                table.setRowCount(len(zones))
                table.setColumnCount(5)
                table.setHorizontalHeaderLabels(["Zone", "Residential", "Commercial", "Industrial", "Total"])
                
                for row, (zone_name, loads) in enumerate(zones.items()):
                    total_load = sum(loads.values())
                    table.setItem(row, 0, QTableWidgetItem(zone_name))
                    table.setItem(row, 1, QTableWidgetItem(f"{loads.get('residential', 0):.2f}"))
                    table.setItem(row, 2, QTableWidgetItem(f"{loads.get('commercial', 0):.2f}"))
                    table.setItem(row, 3, QTableWidgetItem(f"{loads.get('industrial', 0):.2f}"))
                    table.setItem(row, 4, QTableWidgetItem(f"{total_load:.2f}"))
                
                table.resizeColumnsToContents()
                
                # Create table tab with export button
                from qgis.PyQt.QtWidgets import QWidget
                table_widget = QWidget()
                table_layout = QVBoxLayout()
                
                # Export button
                export_button = QPushButton(f"Export {period} to CSV")
                export_button.clicked.connect(lambda checked, t=table, p=period: self.export_table_to_csv(t, f"historical_analysis_{p}"))
                
                table_layout.addWidget(export_button)
                table_layout.addWidget(table)
                table_widget.setLayout(table_layout)
                
                tab_widget.addTab(table_widget, period)
            
            layout.addWidget(tab_widget)
            
            # Close button
            close_button = QPushButton("Close")
            close_button.clicked.connect(dialog.accept)
            layout.addWidget(close_button)
            
            dialog.setLayout(layout)
            dialog.exec_()
            
        except Exception as e:
            LOGGER.error(f"Error showing results dialog: {e}")